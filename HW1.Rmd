---
title: "Homework #1"
author: "David Nemirovsky"
output: github_document
date: 2/14/21
--- 

```{r setup, include=FALSE}
library(tidyverse)
library(ISLR)
library(glmnet)
library(caret)
library(corrplot)
library(plotmo)

knitr::opts_chunk$set(
  fig.width = 7,
  fig.asp = .6,
  out.width = "95%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(37564)
```

In this exercise, we will predict solubility of compounds using their chemical structures. The training data are in the file "solubility_train.csv" and the test data are in "solubility_test.csv". Among the 228 predictors, 208 are binary variables that indicate the presence or absence of a particular chemical substructure, 16 are count features, such as the number of bonds or the number of bromine atoms, and 4 are continuous features, such as molecular weight or surface area. The response is in the column "Solubility" (the last column).

(a) Fit a linear model using least squares on the training data and calculate the mean squared error using the test data.

+ First, let's read in the data:

```{r read, message = F}
train_df = read_csv("solubility_train.csv")
test_df = read_csv("solubility_test.csv")
```

+ Next, let's create a linear model with 10-fold CV:

```{r lm, warning = F}
set.seed(37564)
ctrl = trainControl(method = "cv", number = 10)
model_lm = train(Solubility~., 
               data = train_df, 
               method = "lm", 
               trControl = ctrl)

model_lm$finalModel$coefficients %>% 
  broom::tidy() %>% 
  knitr::kable(col.names = c("Predictor", "Beta Value"))
```

+ Now, let's calculate the MSE using the test data:

```{r mse lm}
lm_pred = predict(model_lm, newdata = test_df)
mse_lm = mean((lm_pred - test_df$Solubility)^2)
```

+ Therefore, the MSE of this linear model is **`r round(mse_lm, 4)`**.

(b) Fit a ridge regression model on the training data, with $\lambda$ chosen by cross-validation. Report the test error.

+ Use `glmnet` to identify tuning parameters for $\lambda$, then fit a 10-fold CV ridge model on training data:

```{r ridge, warning = F}
set.seed(37564)

x = model.matrix(Solubility ~ ., train_df)[ ,-1]
y = train_df$Solubility

tuning_model = cv.glmnet(x, y, alpha = 0, nlambda = 200)
plot(tuning_model)

#Set lambda parameters:
model_ridge = cv.glmnet(x, y, alpha = 0, lambda = exp(seq(7, -5, length = 100)))

plot(model_ridge)
abline(h = (model_ridge$cvm + model_ridge$cvsd)[which.min(model_ridge$cvm)], col = 3, lwd = 0.1)

coef_ridge = predict(model_ridge, s = model_ridge$lambda.min, type = "coefficients")
coef_ridge %>% 
  broom::tidy() %>% 
  select(row, value) %>% 
  knitr::kable(col.names = c("Predictor", "Beta Value"))
```

+ Using the above ridge model, the $\lambda_{min}$ was found to be **`r round(model_ridge$lambda.min,4)`** and the $\lambda_{1SE}$ was found to be **`r round(model_ridge$lambda.1se,4)`**.

+ Now, calculate the MSE of the ridge model:

```{r mse ridge}
x_test = model.matrix(Solubility ~ ., test_df)[ ,-1]
ridge_pred = predict(model_ridge, newx = x_test, 
             s = "lambda.min", type = "response")
mse_ridge = mean((ridge_pred - test_df$Solubility)^2)
```

+ Therefore, the MSE of this ridge regression model, using $\lambda_{min}$, is **`r round(mse_ridge, 4)`**.

(c) Fit a lasso model on the training data, with $\lambda$ chosen by cross-validation. Report the test error and the number of non-zero coeffcient estimates in your model.

+ Use `glmnet` to identify tuning parameters for $\lambda$, then fit a 10-fold CV lasso model on training data:

```{r laso, warning = F}
set.seed(37564)

tuning_model2 = cv.glmnet(x, y, alpha = 1, nlambda = 200)
plot(tuning_model2)

#Set lambda parameters:
model_lasso = cv.glmnet(x, y, alpha = 1, lambda = exp(seq(1, -8, length = 100)))

plot(model_lasso)
abline(h = (model_lasso$cvm + model_lasso$cvsd)[which.min(model_lasso$cvm)], col = 3, lwd = 0.1)

coef_lasso = predict(model_lasso, s = model_lasso$lambda.min, type = "coefficients")
pred_names = coef_ridge %>% broom::tidy() %>% select(row)
coef_lasso[ ,1] %>% 
  as_tibble() %>% 
  cbind(pred_names) %>% 
  select(row, value) %>% 
  knitr::kable(col.names = c("Predictor", "Beta Value"))
```

+ Using the above ridge model, the $\lambda_{min}$ was found to be **`r round(model_lasso$lambda.min,4)`** and the $\lambda_{1SE}$ was found to be **`r round(model_lasso$lambda.1se,4)`**. There are **`r coef_lasso[ ,1] %>% as_tibble() %>% filter(value != 0) %>% nrow()`** non-zero estimates in the lasso model.

+ Now, calculate the MSE of the lasso model:

```{r mse lasso}
lasso_pred = predict(model_lasso, newx = x_test, 
             s = "lambda.min", type = "response")
mse_lasso = mean((lasso_pred - test_df$Solubility)^2)
```

+ Therefore, the MSE of this ridge regression model, using $\lambda_{min}$ with `r coef_lasso[ ,1] %>% as_tibble() %>% filter(value != 0) %>% nrow()` predictors, is **`r round(mse_lasso, 4)`**.

(d) Fit a principle component regression model on the training data, with M chosen by cross-validation. Report the test error and the value ofM selected by cross-validation.

